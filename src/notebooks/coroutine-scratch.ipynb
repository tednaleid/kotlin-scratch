{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-09T21:08:38.373203Z",
     "start_time": "2024-03-09T21:08:38.318354Z"
    }
   },
   "outputs": [],
   "source": [
    "%use coroutines"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting producer\n",
      "sending 1\n",
      "sent 1\n",
      "sending 2\n",
      "launching\n",
      "final\n",
      "sent 2\n",
      "sending 3\n",
      "sent 3\n",
      "sending 4\n",
      "sent 4\n",
      "sending 5\n",
      "processed 1\n",
      "sent 5\n",
      "sending 6\n",
      "processed 2\n",
      "Cancelling\n",
      "done blocking\n"
     ]
    }
   ],
   "source": [
    "import kotlinx.coroutines.channels.Channel\n",
    "import kotlinx.coroutines.delay\n",
    "import kotlinx.coroutines.launch\n",
    "import kotlinx.coroutines.runBlocking\n",
    "\n",
    "runBlocking {\n",
    "    val channel = Channel<Int>(1)\n",
    "    val outputChannel = Channel<Int>(1)\n",
    "\n",
    "    val inputJob = launch {\n",
    "        println(\"starting producer\")\n",
    "//        delay(200)\n",
    "        (1..10).forEach {\n",
    "            println(\"sending $it\")\n",
    "            channel.send(it)\n",
    "            println(\"sent $it\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val processor =launch {\n",
    "        println(\"launching\")\n",
    "        for(it in channel) {\n",
    "//            delay(100)\n",
    "            outputChannel.send(it)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    launch {\n",
    "        println(\"final\")\n",
    "        for(it in outputChannel) {\n",
    "            delay(100)\n",
    "            println(\"processed $it\")\n",
    "            if(it == 2) {\n",
    "                println(\"Cancelling\")\n",
    "                inputJob.cancel()\n",
    "                processor.cancel()\n",
    "                cancel()\n",
    "                return@launch\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "}\n",
    "println(\"done blocking\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T21:08:38.658658Z",
     "start_time": "2024-03-09T21:08:38.373834Z"
    }
   },
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use a pool of workers to handle events, but publish them in order\n",
    "\n",
    "When we have an event we publish it along with a Deferred to two channels:\n",
    "- we hash the key and send it to the worker that corresponds to the hash, it will complete the Deferred when it is done\n",
    "- we also publish the Deferred to a separate channel that is a proxy for the Kafka publisher, it will await the completion of event processing \n",
    "\n",
    "This means we maintain the original order, but allow the work to be fanned out to multiple workers in a consistent way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that the Finished messages are in the same order as the orginal events\n",
      "marked as completed: EventResult(event=Event(key=key2, value=value2), processedValue=Processed by 2: value2)\n",
      "marked as completed: EventResult(event=Event(key=key1, value=value1), processedValue=Processed by 1: value1)\n",
      "marked as completed: EventResult(event=Event(key=key0, value=value0), processedValue=Processed by 0: value0)\n",
      "Finished: EventResult(event=Event(key=key0, value=value0), processedValue=Processed by 0: value0)\n",
      "Finished: EventResult(event=Event(key=key1, value=value1), processedValue=Processed by 1: value1)\n",
      "Finished: EventResult(event=Event(key=key2, value=value2), processedValue=Processed by 2: value2)\n",
      "marked as completed: EventResult(event=Event(key=key3, value=value3), processedValue=Processed by 3: value3)\n",
      "Finished: EventResult(event=Event(key=key3, value=value3), processedValue=Processed by 3: value3)\n",
      "marked as completed: EventResult(event=Event(key=key6, value=value6), processedValue=Processed by 2: value6)\n",
      "marked as completed: EventResult(event=Event(key=key4, value=value4), processedValue=Processed by 0: value4)\n",
      "Finished: EventResult(event=Event(key=key4, value=value4), processedValue=Processed by 0: value4)\n",
      "marked as completed: EventResult(event=Event(key=key7, value=value7), processedValue=Processed by 3: value7)\n",
      "marked as completed: EventResult(event=Event(key=key5, value=value5), processedValue=Processed by 1: value5)\n",
      "Finished: EventResult(event=Event(key=key5, value=value5), processedValue=Processed by 1: value5)\n",
      "Finished: EventResult(event=Event(key=key6, value=value6), processedValue=Processed by 2: value6)\n",
      "Finished: EventResult(event=Event(key=key7, value=value7), processedValue=Processed by 3: value7)\n",
      "marked as completed: EventResult(event=Event(key=key8, value=value8), processedValue=Processed by 0: value8)\n",
      "Finished: EventResult(event=Event(key=key8, value=value8), processedValue=Processed by 0: value8)\n",
      "marked as completed: EventResult(event=Event(key=key9, value=value9), processedValue=Processed by 1: value9)\n",
      "Finished: EventResult(event=Event(key=key9, value=value9), processedValue=Processed by 1: value9)\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": "true"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kotlinx.coroutines.*\n",
    "import kotlinx.coroutines.channels.Channel\n",
    "import kotlin.random.Random\n",
    "\n",
    "data class Event(val key: String, val value: String)\n",
    "data class EventResult(val event: Event, val processedValue: String)\n",
    "\n",
    "fun CoroutineScope.launchEventWorker(workerId: Int, channel: Channel<Pair<Event, CompletableDeferred<EventResult>>>) =\n",
    "    launch {\n",
    "        for ((event, completion) in channel) {\n",
    "            // random delay to simulate work\n",
    "            delay(Random.nextLong(2_000L))\n",
    "            val result = EventResult(event, \"Processed by $workerId: ${event.value}\")\n",
    "            completion.complete(result)\n",
    "            println(\"marked as completed: $result\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun CoroutineScope.launchKafkaPublisher(channel: Channel<CompletableDeferred<EventResult>>) =\n",
    "    launch {\n",
    "        for (completion in channel) {\n",
    "            val result = completion.await()\n",
    "            println(\"Finished: $result\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun main() = runBlocking {\n",
    "    val numberOfWorkers = 4 // Number of workers\n",
    "    val workersChannels = List(numberOfWorkers) { Channel<Pair<Event, CompletableDeferred<EventResult>>>(2) }\n",
    "    val kafkaSendChannel = Channel<CompletableDeferred<EventResult>>(100)\n",
    "\n",
    "    workersChannels.forEachIndexed { index, channel ->\n",
    "        launchEventWorker(index, channel)\n",
    "    }\n",
    "\n",
    "    launchKafkaPublisher(kafkaSendChannel)\n",
    "    \n",
    "    // emulate kafka consumer which is getting via polling and will send values to the appropriate worker\n",
    "    repeat(10) { i ->\n",
    "        // dummy event with a key/value that shows what offset we're at\n",
    "        val eventData = Event(\"key$i\", \"value$i\")\n",
    "        \n",
    "        val deferred = CompletableDeferred<EventResult>()\n",
    "        \n",
    "        // spread the work across the pool of workers \n",
    "        val workerIndex = i % numberOfWorkers\n",
    "        \n",
    "        // send the event and the deferred to the worker for it to complete\n",
    "        workersChannels[workerIndex].send(eventData to deferred)\n",
    "        \n",
    "        // also send the deferred to the kafka publisher, we're maintaining the original order of events\n",
    "        // it will wait for the deferred to be completed by a worker\n",
    "        kafkaSendChannel.send(deferred)\n",
    "    }\n",
    "    \n",
    "    delay(10_000)\n",
    "    println(\"Done\")\n",
    "    \n",
    "    // Cleanup: close channels, etc.\n",
    "    workersChannels.forEach { it.close() }\n",
    "    kafkaSendChannel.close()\n",
    "}\n",
    "\n",
    "\n",
    "println(\"Notice that the Finished messages are in the same order as the orginal events\\n\")\n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T21:10:54.191594Z",
     "start_time": "2024-03-09T21:10:44.084395Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This pattern can be extended for acknowledging the kafka publish\n",
    "\n",
    "Could also use a ticker rendesvous channel to do the committing of offsets back to the kafka brokers"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.0",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectDependencies": [
    "kotlin-scratch"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
