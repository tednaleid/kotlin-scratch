{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-10T01:58:36.021165Z",
     "start_time": "2024-03-10T01:58:35.744123Z"
    }
   },
   "outputs": [],
   "source": [
    "%use coroutines"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting producer\n",
      "sending 1\n",
      "sent 1\n",
      "sending 2\n",
      "launching\n",
      "final\n",
      "sent 2\n",
      "sending 3\n",
      "sent 3\n",
      "sending 4\n",
      "sent 4\n",
      "sending 5\n",
      "processed 1\n",
      "sent 5\n",
      "sending 6\n",
      "processed 2\n",
      "Cancelling\n",
      "done blocking\n"
     ]
    }
   ],
   "source": [
    "import kotlinx.coroutines.channels.Channel\n",
    "import kotlinx.coroutines.delay\n",
    "import kotlinx.coroutines.launch\n",
    "import kotlinx.coroutines.runBlocking\n",
    "\n",
    "runBlocking {\n",
    "    val channel = Channel<Int>(1)\n",
    "    val outputChannel = Channel<Int>(1)\n",
    "\n",
    "    val inputJob = launch {\n",
    "        println(\"starting producer\")\n",
    "//        delay(200)\n",
    "        (1..10).forEach {\n",
    "            println(\"sending $it\")\n",
    "            channel.send(it)\n",
    "            println(\"sent $it\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val processor =launch {\n",
    "        println(\"launching\")\n",
    "        for(it in channel) {\n",
    "//            delay(100)\n",
    "            outputChannel.send(it)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    launch {\n",
    "        println(\"final\")\n",
    "        for(it in outputChannel) {\n",
    "            delay(100)\n",
    "            println(\"processed $it\")\n",
    "            if(it == 2) {\n",
    "                println(\"Cancelling\")\n",
    "                inputJob.cancel()\n",
    "                processor.cancel()\n",
    "                cancel()\n",
    "                return@launch\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "}\n",
    "println(\"done blocking\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T01:58:37.412930Z",
     "start_time": "2024-03-10T01:58:36.664295Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use a pool of workers to handle events, but publish them in order\n",
    "\n",
    "When we have an event we publish it along with a Deferred to two channels:\n",
    "- we hash the key and send it to the worker that corresponds to the hash, it will complete the Deferred when it is done\n",
    "- we also publish the Deferred to a separate channel that is a proxy for the Kafka publisher, it will await the completion of event processing \n",
    "\n",
    "This means we maintain the original order, but allow the work to be fanned out to multiple workers in a consistent way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that the Finished messages are in the same order as the orginal events\n",
      "marked as completed: ProcessEventResult(event=Event(key=key0, value=value0), processedValue=Processed by 0: value0)\n",
      "Finished: ProcessEventResult(event=Event(key=key0, value=value0), processedValue=Processed by 0: value0)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key4, value=value4), processedValue=Processed by 0: value4)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key3, value=value3), processedValue=Processed by 3: value3)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key1, value=value1), processedValue=Processed by 1: value1)\n",
      "Finished: ProcessEventResult(event=Event(key=key1, value=value1), processedValue=Processed by 1: value1)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key2, value=value2), processedValue=Processed by 2: value2)\n",
      "Finished: ProcessEventResult(event=Event(key=key2, value=value2), processedValue=Processed by 2: value2)\n",
      "Finished: ProcessEventResult(event=Event(key=key3, value=value3), processedValue=Processed by 3: value3)\n",
      "Finished: ProcessEventResult(event=Event(key=key4, value=value4), processedValue=Processed by 0: value4)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key7, value=value7), processedValue=Processed by 3: value7)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key5, value=value5), processedValue=Processed by 1: value5)\n",
      "Finished: ProcessEventResult(event=Event(key=key5, value=value5), processedValue=Processed by 1: value5)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key8, value=value8), processedValue=Processed by 0: value8)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key6, value=value6), processedValue=Processed by 2: value6)\n",
      "Finished: ProcessEventResult(event=Event(key=key6, value=value6), processedValue=Processed by 2: value6)\n",
      "Finished: ProcessEventResult(event=Event(key=key7, value=value7), processedValue=Processed by 3: value7)\n",
      "Finished: ProcessEventResult(event=Event(key=key8, value=value8), processedValue=Processed by 0: value8)\n",
      "marked as completed: ProcessEventResult(event=Event(key=key9, value=value9), processedValue=Processed by 1: value9)\n",
      "Finished: ProcessEventResult(event=Event(key=key9, value=value9), processedValue=Processed by 1: value9)\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": "true"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kotlinx.coroutines.*\n",
    "import kotlinx.coroutines.channels.Channel\n",
    "import kotlin.random.Random\n",
    "\n",
    "data class Event(val key: String, val value: String)\n",
    "data class ProcessEventResult(val event: Event, val processedValue: String)\n",
    "\n",
    "fun CoroutineScope.launchEventWorker(workerId: Int, channel: Channel<Pair<Event, CompletableDeferred<ProcessEventResult>>>) =\n",
    "    launch {\n",
    "        for ((event, completion) in channel) {\n",
    "            // random delay to simulate work\n",
    "            delay(Random.nextLong(2_000L))\n",
    "            val result = ProcessEventResult(event, \"Processed by $workerId: ${event.value}\")\n",
    "            completion.complete(result)\n",
    "            println(\"marked as completed: $result\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun CoroutineScope.launchKafkaPublisher(channel: Channel<CompletableDeferred<ProcessEventResult>>) =\n",
    "    launch {\n",
    "        for (completion in channel) {\n",
    "            val result = completion.await()\n",
    "            println(\"Finished: $result\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun main() = runBlocking {\n",
    "    val numberOfWorkers = 4 // Number of workers\n",
    "    val workersChannels = List(numberOfWorkers) { Channel<Pair<Event, CompletableDeferred<ProcessEventResult>>>(2) }\n",
    "    val kafkaSendChannel = Channel<CompletableDeferred<ProcessEventResult>>(100)\n",
    "\n",
    "    workersChannels.forEachIndexed { index, channel ->\n",
    "        launchEventWorker(index, channel)\n",
    "    }\n",
    "\n",
    "    launchKafkaPublisher(kafkaSendChannel)\n",
    "    \n",
    "    // emulate kafka consumer which is getting via polling and will send values to the appropriate worker\n",
    "    repeat(10) { i ->\n",
    "        // dummy event with a key/value that shows what offset we're at\n",
    "        val eventData = Event(\"key$i\", \"value$i\")\n",
    "        \n",
    "        val deferred = CompletableDeferred<ProcessEventResult>()\n",
    "        \n",
    "        // spread the work across the pool of workers \n",
    "        val workerIndex = i % numberOfWorkers\n",
    "        \n",
    "        // send the event and the deferred to the worker for it to complete\n",
    "        workersChannels[workerIndex].send(eventData to deferred)\n",
    "        \n",
    "        // also send the deferred to the kafka publisher, we're maintaining the original order of events\n",
    "        // it will wait for the deferred to be completed by a worker\n",
    "        kafkaSendChannel.send(deferred)\n",
    "    }\n",
    "    \n",
    "    delay(10_000)\n",
    "    println(\"Done\")\n",
    "    \n",
    "    // Cleanup: close channels, etc.\n",
    "    workersChannels.forEach { it.close() }\n",
    "    kafkaSendChannel.close()\n",
    "}\n",
    "\n",
    "\n",
    "println(\"Notice that the Finished messages are in the same order as the orginal events\\n\")\n",
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T01:59:15.413561Z",
     "start_time": "2024-03-10T01:59:05.085449Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Refactored version that decouples the event source (kafka consumer) from what happens to those events\n",
    "\n",
    "### This pattern can be extended for acknowledging the kafka publish\n",
    "\n",
    "Could also use a ticker rendesvous channel to do the committing of offsets back to the kafka brokers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import kotlinx.coroutines.*\n",
    "import kotlinx.coroutines.channels.Channel\n",
    "import kotlinx.coroutines.channels.ReceiveChannel\n",
    "import kotlinx.coroutines.channels.SendChannel\n",
    "import kotlinx.coroutines.channels.ticker\n",
    "import kotlinx.coroutines.future.asCompletableFuture\n",
    "import java.util.concurrent.CompletableFuture\n",
    "import java.util.concurrent.ConcurrentHashMap\n",
    "import kotlin.random.Random\n",
    "\n",
    "data class UpstreamEvent(val partition: Int, val offset: Int, val key: String, val value: String) {\n",
    "    override fun toString(): String {\n",
    "        return \"$partition:$offset $key -> $value\"\n",
    "    }\n",
    "}\n",
    "\n",
    "data class DownstreamEvent(val key: String, val value: String) {\n",
    "    override fun toString(): String {\n",
    "        return \"$key -> $value\"\n",
    "    }\n",
    "}\n",
    "\n",
    "sealed class TransformResult {\n",
    "    data class Forward(val downstreamEvent: DownstreamEvent) : TransformResult()\n",
    "\n",
    "    // allow for many events to be published downstream for a single upstream event\n",
    "    data class ForwardMany(val downstreamEvents: List<DownstreamEvent>) : TransformResult()\n",
    "    data class Drop(val reason: String) : TransformResult()\n",
    "    data class Error(val error: Throwable) : TransformResult()\n",
    "}\n",
    "\n",
    "// mock RecordMetadata\n",
    "data class RecordMetadata(val topic: String, val partition: Int, val offset: Long)\n",
    "\n",
    "data class EventTransformDeferredResult(\n",
    "    val upstreamEvent: UpstreamEvent,\n",
    "    val deferred: CompletableDeferred<TransformResult>\n",
    ")\n",
    "\n",
    "\n",
    "// kafka publishing uses completable futures, not deferreds, this will be completed for\n",
    "// publish many when the last event is published\n",
    "data class TransformedEventPublishFuture(\n",
    "    val upstreamEvent: UpstreamEvent,\n",
    "    val publishFuture: CompletableFuture<RecordMetadata>\n",
    ")\n",
    "\n",
    "// does the per-event work and marks the deferred as completed when work is done\n",
    "fun CoroutineScope.launchEventWorker(\n",
    "    eventChannel: ReceiveChannel<EventTransformDeferredResult>,\n",
    "    transformEvent: suspend (UpstreamEvent) -> TransformResult\n",
    ") = launch(Dispatchers.Default) {// using Dispatchers.Default as this is constrained by CPU work and is limited to the number of CPUs, consider Dispatchers.IO if we expect users to block\n",
    "    for ((upstreamEvent, completion) in eventChannel) {\n",
    "        val result = transformEvent(upstreamEvent)\n",
    "        completion.complete(result)\n",
    "    }\n",
    "}\n",
    "\n",
    "// this function needs to react differently based on the type of result, we still want to send it downstream regardless\n",
    "// of the type of results so that we can commit progress as we're done with processing that event (or we blow up if it is an error)\n",
    "fun CoroutineScope.launchKafkaPublisher(\n",
    "    channel: ReceiveChannel<EventTransformDeferredResult>,\n",
    "    kafkaAcknowledgementChannel: SendChannel<TransformedEventPublishFuture>\n",
    ") =\n",
    "    launch {\n",
    "        var publishedOffset: Long = 1\n",
    "        for (eventTransformeDeferredResult in channel) {\n",
    "            val result = eventTransformeDeferredResult.deferred.await()\n",
    "\n",
    "            when (result) {\n",
    "                is TransformResult.Forward -> {\n",
    "                    println(\"${Thread.currentThread().name} Publishing: ${eventTransformeDeferredResult.upstreamEvent} -> ${result.downstreamEvent}\")\n",
    "                    kafkaAcknowledgementChannel.send(\n",
    "                        TransformedEventPublishFuture(\n",
    "                            eventTransformeDeferredResult.upstreamEvent,\n",
    "                            CompletableFuture.completedFuture(RecordMetadata(\"topic\", 0, publishedOffset++))\n",
    "                        )\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                is TransformResult.ForwardMany -> {\n",
    "                    // TODO would want to commit only after on the last event\n",
    "                    // we could wrap all of the individual acks in a single future and send that downstream\n",
    "                    result.downstreamEvents.forEach {\n",
    "                        println(\"Publishing: ${eventTransformeDeferredResult.upstreamEvent} -> $it\")\n",
    "                        kafkaAcknowledgementChannel.send(\n",
    "                            TransformedEventPublishFuture(\n",
    "                                eventTransformeDeferredResult.upstreamEvent,\n",
    "                                CompletableFuture.completedFuture(RecordMetadata(\"topic\", 0, publishedOffset++))\n",
    "                            )\n",
    "                        )\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                is TransformResult.Drop -> {\n",
    "                    println(\"${Thread.currentThread().name} Publishing: ${eventTransformeDeferredResult.upstreamEvent} -> Dropped: ${result.reason}\")\n",
    "\n",
    "                    // still need to send downstream to the kafka acknowledger for commit purposes, sending already completed\n",
    "                    kafkaAcknowledgementChannel.send(\n",
    "                        TransformedEventPublishFuture(\n",
    "                            eventTransformeDeferredResult.upstreamEvent,\n",
    "                            // TODO don't actually send RecordMetadata for dropped events, optional or null?\n",
    "                            CompletableFuture.completedFuture(RecordMetadata(\"topic\", 0, -1))\n",
    "                        )\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                is TransformResult.Error -> {\n",
    "                    // TODO blow up?  Still send downstream?\n",
    "                    println(\"${Thread.currentThread().name} Publishing: ${eventTransformeDeferredResult.upstreamEvent} -> Error: ${result.error}\")\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun CoroutineScope.launchKafkaAcknowledger(\n",
    "    channel: ReceiveChannel<TransformedEventPublishFuture>,\n",
    "    partitionToOffset: ConcurrentHashMap<Int, Long>\n",
    ") =\n",
    "    launch(Dispatchers.IO) { // using Dispatchers.IO as this will block on the kafka future\n",
    "        for (transformedEventPublishFuture in channel) {\n",
    "            val recordMetadata = transformedEventPublishFuture.publishFuture.join()\n",
    "            println(\"${Thread.currentThread().name} Acked: ${transformedEventPublishFuture.upstreamEvent} -> $recordMetadata\")\n",
    "            if(recordMetadata.offset >= 0) {\n",
    "                partitionToOffset[recordMetadata.partition] = recordMetadata.offset\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun CoroutineScope.launchKafkaCommitter(\n",
    "    tickerChannel: ReceiveChannel<Unit>,\n",
    "    partitionToOffset: ConcurrentHashMap<Int, Long> // TODO should be a TopicPartition to Long\n",
    ") = launch {\n",
    "    for (unit in tickerChannel) {\n",
    "        partitionToOffset.replaceAll { partition, offset ->\n",
    "            // if we have a positive value, we've made progress on this partition since the last tick\n",
    "            if (offset >= 0) {\n",
    "                println(\"${Thread.currentThread().name} Tick - Committing $partition -> $offset\")\n",
    "            } else {\n",
    "                println(\"${Thread.currentThread().name} Tick - nothing new to commit!\")\n",
    "            }\n",
    "            -1L// replace with a negative value so we don't commit on this partition again till we've made real progress\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// 1. eventSource submits events that are sent to the appropriate worker, and sends an uncompleted deferred to the kafka publisher\n",
    "// 2. the worker calls the supplied `transformEvent` and completes the deferred when done with the work\n",
    "// 3. the kafka publisher awaits the completion of the transformed event and maintains the original order of events\n",
    "//       it then does an async publish of the event and sends the future to the kafka acknowledger\n",
    "// 4. the kafka acknowledger awaits the completion of the publish and then updates the partitionToOffset map\n",
    "suspend fun CoroutineScope.withActors(\n",
    "    numberOfWorkers: Int,\n",
    "    transformEvent: suspend (UpstreamEvent) -> TransformResult,\n",
    "    eventSource: suspend (suspend (UpstreamEvent) -> Unit) -> Unit\n",
    ") {\n",
    "    val partitionToOffset = ConcurrentHashMap<Int, Long>()\n",
    "\n",
    "    // in real code these should have much larger buffer sizes, the ack one especially needs to be large enough so it\n",
    "    // aren't blocking the publishing of events\n",
    "    val workersChannels =\n",
    "        List(numberOfWorkers) { Channel<EventTransformDeferredResult>(2) }\n",
    "    val readyToPublishChannel = Channel<EventTransformDeferredResult>(10)\n",
    "    val kafkaAcknowledgementChannel = Channel<TransformedEventPublishFuture>(10)\n",
    "    val tickerChannel = ticker(delayMillis = 2000)\n",
    "\n",
    "    workersChannels.forEach { channel ->\n",
    "        launchEventWorker(channel, transformEvent)\n",
    "    }\n",
    "\n",
    "    launchKafkaPublisher(readyToPublishChannel, kafkaAcknowledgementChannel)\n",
    "\n",
    "    launchKafkaAcknowledger(kafkaAcknowledgementChannel, partitionToOffset)\n",
    "\n",
    "    launchKafkaCommitter(tickerChannel, partitionToOffset)\n",
    "\n",
    "    suspend fun submitEvent(event: UpstreamEvent) {\n",
    "        val deferred = CompletableDeferred<TransformResult>()\n",
    "        val eventTransformDeferredResult = EventTransformDeferredResult(event, deferred)\n",
    "        val workerIndex = event.key.hashCode() % numberOfWorkers\n",
    "        workersChannels[workerIndex].send(eventTransformDeferredResult)\n",
    "        readyToPublishChannel.send(eventTransformDeferredResult)\n",
    "    }\n",
    "\n",
    "    eventSource(::submitEvent)\n",
    "\n",
    "    delay(10_000)\n",
    "    println(\"Done\")\n",
    "\n",
    "    // Cleanup: close channels, etc.\n",
    "    workersChannels.forEach { it.close() }\n",
    "    readyToPublishChannel.close()\n",
    "    kafkaAcknowledgementChannel.close()\n",
    "    tickerChannel.cancel()\n",
    "}\n",
    "\n",
    "suspend fun transformEvent(event: UpstreamEvent): TransformResult {\n",
    "    // simulate work, random delay up to 2 seconds\n",
    "    println(\"${Thread.currentThread().name} Transforming event: $event\")\n",
    "    delay(Random.nextLong(2_000L))\n",
    "    if (event.offset % 3 == 0) {\n",
    "        return TransformResult.Drop(\"Dropping every 3rd event\")\n",
    "    }\n",
    "    return TransformResult.Forward(DownstreamEvent(event.key, \"Processed by worker: ${event.value}\"))\n",
    "}\n",
    "\n",
    "// event from poll -> submitEvent -> worker[<for hashed key>] -> kafkaPublisher -> kafkaAcknowledger && kafkaCommitter\n",
    "// \"Polled\" -> \"Transforming\" -> \"Publishing\" -> \"Acked\" &&  asynchronous \"Tick\" will commit updated progress every 2 seconds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T07:52:42.111984Z",
     "start_time": "2024-03-10T07:52:41.930707Z"
    }
   },
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main polling for events to submit\n",
      "main Polled upstream event: 0:1 key1 -> value1\n",
      "main Polled upstream event: 0:2 key2 -> value2\n",
      "main Polled upstream event: 0:3 key3 -> value3\n",
      "main Polled upstream event: 0:4 key4 -> value4\n",
      "main Polled upstream event: 0:5 key5 -> value5\n",
      "main Polled upstream event: 0:6 key6 -> value6\n",
      "DefaultDispatcher-worker-4 Transforming event: 0:1 key1 -> value1\n",
      "DefaultDispatcher-worker-7 Transforming event: 0:4 key4 -> value4\n",
      "DefaultDispatcher-worker-8 Transforming event: 0:2 key2 -> value2\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:3 key3 -> value3\n",
      "main Polled upstream event: 0:7 key7 -> value7\n",
      "main Polled upstream event: 0:8 key8 -> value8\n",
      "main Polled upstream event: 0:9 key9 -> value9\n",
      "main Polled upstream event: 0:10 key10 -> value10\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:5 key5 -> value5\n",
      "main Publishing: 0:1 key1 -> value1 -> key1 -> Processed by worker: value1\n",
      "DefaultDispatcher-worker-6 Acked: 0:1 key1 -> value1 -> RecordMetadata(topic=topic, partition=0, offset=1)\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:7 key7 -> value7\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:8 key8 -> value8\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:6 key6 -> value6\n",
      "main Publishing: 0:2 key2 -> value2 -> key2 -> Processed by worker: value2\n",
      "DefaultDispatcher-worker-6 Acked: 0:2 key2 -> value2 -> RecordMetadata(topic=topic, partition=0, offset=2)\n",
      "main Publishing: 0:3 key3 -> value3 -> Dropped: Dropping every 3rd event\n",
      "main Publishing: 0:4 key4 -> value4 -> key4 -> Processed by worker: value4\n",
      "DefaultDispatcher-worker-6 Acked: 0:3 key3 -> value3 -> RecordMetadata(topic=topic, partition=0, offset=-1)\n",
      "DefaultDispatcher-worker-6 Acked: 0:4 key4 -> value4 -> RecordMetadata(topic=topic, partition=0, offset=3)\n",
      "main Tick - Committing 0 -> 3\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:9 key9 -> value9\n",
      "main Publishing: 0:5 key5 -> value5 -> key5 -> Processed by worker: value5\n",
      "main Publishing: 0:6 key6 -> value6 -> Dropped: Dropping every 3rd event\n",
      "main Publishing: 0:7 key7 -> value7 -> key7 -> Processed by worker: value7\n",
      "main Publishing: 0:8 key8 -> value8 -> key8 -> Processed by worker: value8\n",
      "DefaultDispatcher-worker-6 Acked: 0:5 key5 -> value5 -> RecordMetadata(topic=topic, partition=0, offset=4)\n",
      "DefaultDispatcher-worker-6 Acked: 0:6 key6 -> value6 -> RecordMetadata(topic=topic, partition=0, offset=-1)\n",
      "DefaultDispatcher-worker-6 Acked: 0:7 key7 -> value7 -> RecordMetadata(topic=topic, partition=0, offset=5)\n",
      "DefaultDispatcher-worker-6 Acked: 0:8 key8 -> value8 -> RecordMetadata(topic=topic, partition=0, offset=6)\n",
      "DefaultDispatcher-worker-6 Transforming event: 0:10 key10 -> value10\n",
      "main Publishing: 0:9 key9 -> value9 -> Dropped: Dropping every 3rd event\n",
      "DefaultDispatcher-worker-6 Acked: 0:9 key9 -> value9 -> RecordMetadata(topic=topic, partition=0, offset=-1)\n",
      "main Publishing: 0:10 key10 -> value10 -> key10 -> Processed by worker: value10\n",
      "DefaultDispatcher-worker-6 Acked: 0:10 key10 -> value10 -> RecordMetadata(topic=topic, partition=0, offset=7)\n",
      "main Tick - Committing 0 -> 7\n",
      "main Tick - nothing new to commit!\n",
      "main Tick - nothing new to commit!\n",
      "main Tick - nothing new to commit!\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "// this is the \"main\" loop that would use a real kafka consumer to poll for events and submit them to the actors\n",
    "runBlocking {\n",
    "    Thread.currentThread().name = \"main\"\n",
    "    val numberOfWorkers = 4\n",
    "\n",
    "    // emulate kafka consumer which is getting via polling and will send values to the appropriate worker\n",
    "    withActors(numberOfWorkers, ::transformEvent) { submitEvent ->\n",
    "        val partition = 0\n",
    "\n",
    "        println(\"${Thread.currentThread().name} polling for events to submit\")\n",
    "        // emulate kafka consumer which is getting via polling and will send values to the appropriate worker\n",
    "        (1..10).forEach { i ->\n",
    "            val eventData = UpstreamEvent(partition, i, \"key$i\", \"value$i\")\n",
    "            println(\"${Thread.currentThread().name} Polled upstream event: $eventData\")\n",
    "            submitEvent(eventData)\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T07:52:56.646352Z",
     "start_time": "2024-03-10T07:52:46.436900Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.0",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "projectDependencies": [
    "kotlin-scratch"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
